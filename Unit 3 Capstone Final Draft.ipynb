{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 Capstone Project\n",
    "  ## Matthew Kennedy, August 2017\n",
    "\n",
    "   ## Section 1: Overview of Dataset and Analysis of Data\n",
    "   \n",
    "   The dataset used in this project comes from Kaggle user \"CNuge.\" The dataset contains historical stock prices over the last five years for all companies in the S&P 500 index and can be found at https://www.kaggle.com/camnugent/sandp500. This project will use the files that have the historical prices for individual stocks.   \n",
    "       \n",
    "   The dataset contains the following columns: \n",
    "       \n",
    "       Date - In the format of yy-mm-dd\n",
    "       Open - Price of the stock in USD at market open\n",
    "       High - Highest price reached in the day\n",
    "       Low - Lowest price reached in the day\n",
    "       Close - The price the stock had at the end of the day\n",
    "       Volume - Number of shares traded\n",
    "       Name - The stock's ticker name\n",
    "       \n",
    "   The user collected the data by using the python library, 'pandas_datareader,' to scrape Google Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maken\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This project will use the historical prices of GOOGL\n",
    "\n",
    "# Read the Dataset, store the original\n",
    "# This is the filepath on my laptop:\n",
    "#original = pd.read_csv('C:\\\\Users\\\\mkennedy\\\\sandp500\\\\individual_stocks_5yr\\\\GOOGL_data.csv', encoding='utf-8-sig')\n",
    "# This is the filepath on my desktop:\n",
    "original = pd.read_csv('D:\\\\Data\\\\sandp500\\\\GOOGL_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/13/2012</td>\n",
       "      <td>324.03</td>\n",
       "      <td>330.41</td>\n",
       "      <td>323.66</td>\n",
       "      <td>330.34</td>\n",
       "      <td>3268073</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/14/2012</td>\n",
       "      <td>329.95</td>\n",
       "      <td>336.76</td>\n",
       "      <td>329.83</td>\n",
       "      <td>334.66</td>\n",
       "      <td>3662178</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/15/2012</td>\n",
       "      <td>335.48</td>\n",
       "      <td>337.46</td>\n",
       "      <td>332.38</td>\n",
       "      <td>334.10</td>\n",
       "      <td>2411100</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>334.09</td>\n",
       "      <td>337.66</td>\n",
       "      <td>333.87</td>\n",
       "      <td>336.77</td>\n",
       "      <td>1717691</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/17/2012</td>\n",
       "      <td>337.40</td>\n",
       "      <td>338.96</td>\n",
       "      <td>336.19</td>\n",
       "      <td>338.91</td>\n",
       "      <td>2177896</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close   Volume   Name\n",
       "0  8/13/2012  324.03  330.41  323.66  330.34  3268073  GOOGL\n",
       "1  8/14/2012  329.95  336.76  329.83  334.66  3662178  GOOGL\n",
       "2  8/15/2012  335.48  337.46  332.38  334.10  2411100  GOOGL\n",
       "3  8/16/2012  334.09  337.66  333.87  336.77  1717691  GOOGL\n",
       "4  8/17/2012  337.40  338.96  336.19  338.91  2177896  GOOGL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy a dataframe of the original data to manipulate\n",
    "data = original\n",
    "\n",
    "# Print the headers of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>8/7/2017</td>\n",
       "      <td>947.52</td>\n",
       "      <td>948.96</td>\n",
       "      <td>943.50</td>\n",
       "      <td>945.75</td>\n",
       "      <td>1445754</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>8/8/2017</td>\n",
       "      <td>944.29</td>\n",
       "      <td>952.49</td>\n",
       "      <td>942.48</td>\n",
       "      <td>944.19</td>\n",
       "      <td>1505064</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8/9/2017</td>\n",
       "      <td>938.45</td>\n",
       "      <td>943.76</td>\n",
       "      <td>933.92</td>\n",
       "      <td>940.08</td>\n",
       "      <td>1400852</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8/10/2017</td>\n",
       "      <td>935.00</td>\n",
       "      <td>936.30</td>\n",
       "      <td>921.78</td>\n",
       "      <td>923.59</td>\n",
       "      <td>2707393</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8/11/2017</td>\n",
       "      <td>923.71</td>\n",
       "      <td>933.36</td>\n",
       "      <td>921.22</td>\n",
       "      <td>930.09</td>\n",
       "      <td>1616708</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close   Volume   Name\n",
       "1253   8/7/2017  947.52  948.96  943.50  945.75  1445754  GOOGL\n",
       "1254   8/8/2017  944.29  952.49  942.48  944.19  1505064  GOOGL\n",
       "1255   8/9/2017  938.45  943.76  933.92  940.08  1400852  GOOGL\n",
       "1256  8/10/2017  935.00  936.30  921.78  923.59  2707393  GOOGL\n",
       "1257  8/11/2017  923.71  933.36  921.22  930.09  1616708  GOOGL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the footer to make sure there are no rows of text\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no footers that need to be excluded.\n",
    "There are 1257 rows of stock data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1.258000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>616.760469</td>\n",
       "      <td>621.377719</td>\n",
       "      <td>611.501638</td>\n",
       "      <td>616.599809</td>\n",
       "      <td>2.076615e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>170.726853</td>\n",
       "      <td>171.626054</td>\n",
       "      <td>169.458607</td>\n",
       "      <td>170.631830</td>\n",
       "      <td>1.081167e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>323.320000</td>\n",
       "      <td>326.830000</td>\n",
       "      <td>318.320000</td>\n",
       "      <td>323.910000</td>\n",
       "      <td>5.211410e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>510.217500</td>\n",
       "      <td>514.237500</td>\n",
       "      <td>504.365000</td>\n",
       "      <td>508.212500</td>\n",
       "      <td>1.453572e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>579.000000</td>\n",
       "      <td>583.625000</td>\n",
       "      <td>573.405000</td>\n",
       "      <td>579.170000</td>\n",
       "      <td>1.820138e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>758.737500</td>\n",
       "      <td>765.280000</td>\n",
       "      <td>754.065000</td>\n",
       "      <td>759.822500</td>\n",
       "      <td>2.343574e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1005.490000</td>\n",
       "      <td>1008.610000</td>\n",
       "      <td>996.620000</td>\n",
       "      <td>1004.280000</td>\n",
       "      <td>1.285814e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close        Volume\n",
       "count  1258.000000  1258.000000  1258.000000  1258.000000  1.258000e+03\n",
       "mean    616.760469   621.377719   611.501638   616.599809  2.076615e+06\n",
       "std     170.726853   171.626054   169.458607   170.631830  1.081167e+06\n",
       "min     323.320000   326.830000   318.320000   323.910000  5.211410e+05\n",
       "25%     510.217500   514.237500   504.365000   508.212500  1.453572e+06\n",
       "50%     579.000000   583.625000   573.405000   579.170000  1.820138e+06\n",
       "75%     758.737500   765.280000   754.065000   759.822500  2.343574e+06\n",
       "max    1005.490000  1008.610000   996.620000  1004.280000  1.285814e+07"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The describe method provides some additional information about the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date       object\n",
      "Open      float64\n",
      "High      float64\n",
      "Low       float64\n",
      "Close     float64\n",
      "Volume      int64\n",
      "Name       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The dtypes call will display the data types. \n",
    "# This is used to make sure all numerical values have the correct data type to work with in the models.\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset appears to be clean and easy to work with.\n",
    "\n",
    "Observe the correlations between columns by using seaborn's heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAIHCAYAAABKVYKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCwCgyjRcAABVpuECAKiy/w9o5DA6ld290gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4d98784e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a heatmap to compare the correlation of the columns.\n",
    "import seaborn as sns\n",
    "\n",
    "corrmat = data.corr()\n",
    "\n",
    "# Set up the matplotlib figure.\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "# Draw the heatmap using seaborn\n",
    "sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the values are highly correlated. Creating prediction models based off of time-series data will not be helpful in reaching the goal of this project (to determine whether to buy or sell the at the next opening day). \n",
    "\n",
    "Features will need to be created to generate accurate predictions from the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/13/2012</td>\n",
       "      <td>324.03</td>\n",
       "      <td>330.41</td>\n",
       "      <td>323.66</td>\n",
       "      <td>330.34</td>\n",
       "      <td>3268073</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/14/2012</td>\n",
       "      <td>329.95</td>\n",
       "      <td>336.76</td>\n",
       "      <td>329.83</td>\n",
       "      <td>334.66</td>\n",
       "      <td>3662178</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/15/2012</td>\n",
       "      <td>335.48</td>\n",
       "      <td>337.46</td>\n",
       "      <td>332.38</td>\n",
       "      <td>334.10</td>\n",
       "      <td>2411100</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>334.09</td>\n",
       "      <td>337.66</td>\n",
       "      <td>333.87</td>\n",
       "      <td>336.77</td>\n",
       "      <td>1717691</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/17/2012</td>\n",
       "      <td>337.40</td>\n",
       "      <td>338.96</td>\n",
       "      <td>336.19</td>\n",
       "      <td>338.91</td>\n",
       "      <td>2177896</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close   Volume   Name  Momentum\n",
       "0  8/13/2012  324.03  330.41  323.66  330.34  3268073  GOOGL         0\n",
       "1  8/14/2012  329.95  336.76  329.83  334.66  3662178  GOOGL         1\n",
       "2  8/15/2012  335.48  337.46  332.38  334.10  2411100  GOOGL        -1\n",
       "3  8/16/2012  334.09  337.66  333.87  336.77  1717691  GOOGL         1\n",
       "4  8/17/2012  337.40  338.96  336.19  338.91  2177896  GOOGL         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The momentum will show how many days in a row the stock has moved up or down. \n",
    "\n",
    "# Create a list to store the momentum\n",
    "momentum = [0]\n",
    "i=1\n",
    "# Calculate the momentums and store them in the new column, 'Momentum'\n",
    "for row in data['Close']:\n",
    "    if i < len(data):\n",
    "        if data.Close[i] > data.Close[i-1]:\n",
    "            momentum.append(+1)\n",
    "            i = i+1\n",
    "        elif data.Close[i] < data.Close[i-1]:\n",
    "            momentum.append(-1)\n",
    "            i = i+1\n",
    "\n",
    "data['Momentum'] = momentum\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "0.04848966613672496\n"
     ]
    }
   ],
   "source": [
    "# Print out the total momentum and the average momentum across all rows.\n",
    "total_mom = sum(data.Momentum)\n",
    "print(total_mom)\n",
    "ave_mom = data.Momentum.mean()\n",
    "print(ave_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/13/2012</td>\n",
       "      <td>324.03</td>\n",
       "      <td>330.41</td>\n",
       "      <td>323.66</td>\n",
       "      <td>330.34</td>\n",
       "      <td>3268073</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/14/2012</td>\n",
       "      <td>329.95</td>\n",
       "      <td>336.76</td>\n",
       "      <td>329.83</td>\n",
       "      <td>334.66</td>\n",
       "      <td>3662178</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/15/2012</td>\n",
       "      <td>335.48</td>\n",
       "      <td>337.46</td>\n",
       "      <td>332.38</td>\n",
       "      <td>334.10</td>\n",
       "      <td>2411100</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>334.09</td>\n",
       "      <td>337.66</td>\n",
       "      <td>333.87</td>\n",
       "      <td>336.77</td>\n",
       "      <td>1717691</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/17/2012</td>\n",
       "      <td>337.40</td>\n",
       "      <td>338.96</td>\n",
       "      <td>336.19</td>\n",
       "      <td>338.91</td>\n",
       "      <td>2177896</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close   Volume   Name  Momentum  Streak\n",
       "0  8/13/2012  324.03  330.41  323.66  330.34  3268073  GOOGL         0       0\n",
       "1  8/14/2012  329.95  336.76  329.83  334.66  3662178  GOOGL         1       1\n",
       "2  8/15/2012  335.48  337.46  332.38  334.10  2411100  GOOGL        -1       0\n",
       "3  8/16/2012  334.09  337.66  333.87  336.77  1717691  GOOGL         1       1\n",
       "4  8/17/2012  337.40  338.96  336.19  338.91  2177896  GOOGL         1       2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streak = [0] * len(data)\n",
    "i=1\n",
    "# Calculate the streaks and store them in the new column, 'Streak'\n",
    "for row in data['Close']:\n",
    "    if i < len(data):\n",
    "        if data.Close[i] > data.Close[i-1]:\n",
    "            if streak[i-1] >= 0:\n",
    "                streak[i] = streak[i-1]+1\n",
    "                i = i+1\n",
    "            else:\n",
    "                streak[i]=0\n",
    "                i = i+1\n",
    "        elif data.Close[i] < data.Close[i-1]:\n",
    "            if streak[i-1] <= 0:\n",
    "                streak[i] = streak[i-1]-1\n",
    "                i = i+1\n",
    "            else:\n",
    "                streak[i]=0\n",
    "                i = i+1\n",
    "\n",
    "data['Streak'] = streak\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Streak</th>\n",
       "      <th>Future Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/13/2012</td>\n",
       "      <td>324.03</td>\n",
       "      <td>330.41</td>\n",
       "      <td>323.66</td>\n",
       "      <td>330.34</td>\n",
       "      <td>3268073</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/14/2012</td>\n",
       "      <td>329.95</td>\n",
       "      <td>336.76</td>\n",
       "      <td>329.83</td>\n",
       "      <td>334.66</td>\n",
       "      <td>3662178</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/15/2012</td>\n",
       "      <td>335.48</td>\n",
       "      <td>337.46</td>\n",
       "      <td>332.38</td>\n",
       "      <td>334.10</td>\n",
       "      <td>2411100</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/16/2012</td>\n",
       "      <td>334.09</td>\n",
       "      <td>337.66</td>\n",
       "      <td>333.87</td>\n",
       "      <td>336.77</td>\n",
       "      <td>1717691</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/17/2012</td>\n",
       "      <td>337.40</td>\n",
       "      <td>338.96</td>\n",
       "      <td>336.19</td>\n",
       "      <td>338.91</td>\n",
       "      <td>2177896</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close   Volume   Name  Momentum  \\\n",
       "0  8/13/2012  324.03  330.41  323.66  330.34  3268073  GOOGL         0   \n",
       "1  8/14/2012  329.95  336.76  329.83  334.66  3662178  GOOGL         1   \n",
       "2  8/15/2012  335.48  337.46  332.38  334.10  2411100  GOOGL        -1   \n",
       "3  8/16/2012  334.09  337.66  333.87  336.77  1717691  GOOGL         1   \n",
       "4  8/17/2012  337.40  338.96  336.19  338.91  2177896  GOOGL         1   \n",
       "\n",
       "   Streak  Future Momentum  \n",
       "0       0              1.0  \n",
       "1       1             -1.0  \n",
       "2       0              1.0  \n",
       "3       1              1.0  \n",
       "4       2             -1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 'Future Momentum' feature that the model will attempt to predict.\n",
    "data['Future Momentum'] = data.Momentum.shift(-1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Streak</th>\n",
       "      <th>Future Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>8/7/2017</td>\n",
       "      <td>947.52</td>\n",
       "      <td>948.96</td>\n",
       "      <td>943.50</td>\n",
       "      <td>945.75</td>\n",
       "      <td>1445754</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>8/8/2017</td>\n",
       "      <td>944.29</td>\n",
       "      <td>952.49</td>\n",
       "      <td>942.48</td>\n",
       "      <td>944.19</td>\n",
       "      <td>1505064</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8/9/2017</td>\n",
       "      <td>938.45</td>\n",
       "      <td>943.76</td>\n",
       "      <td>933.92</td>\n",
       "      <td>940.08</td>\n",
       "      <td>1400852</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8/10/2017</td>\n",
       "      <td>935.00</td>\n",
       "      <td>936.30</td>\n",
       "      <td>921.78</td>\n",
       "      <td>923.59</td>\n",
       "      <td>2707393</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8/11/2017</td>\n",
       "      <td>923.71</td>\n",
       "      <td>933.36</td>\n",
       "      <td>921.22</td>\n",
       "      <td>930.09</td>\n",
       "      <td>1616708</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close   Volume   Name  Momentum  \\\n",
       "1253   8/7/2017  947.52  948.96  943.50  945.75  1445754  GOOGL        -1   \n",
       "1254   8/8/2017  944.29  952.49  942.48  944.19  1505064  GOOGL        -1   \n",
       "1255   8/9/2017  938.45  943.76  933.92  940.08  1400852  GOOGL        -1   \n",
       "1256  8/10/2017  935.00  936.30  921.78  923.59  2707393  GOOGL        -1   \n",
       "1257  8/11/2017  923.71  933.36  921.22  930.09  1616708  GOOGL         1   \n",
       "\n",
       "      Streak  Future Momentum  \n",
       "1253       0             -1.0  \n",
       "1254      -1             -1.0  \n",
       "1255      -2             -1.0  \n",
       "1256      -3              1.0  \n",
       "1257       0              NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the last row to get rid of the NaN values\n",
    "data = data.iloc[:len(data)-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Streak</th>\n",
       "      <th>Future Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>8/4/2017</td>\n",
       "      <td>943.95</td>\n",
       "      <td>947.54</td>\n",
       "      <td>939.80</td>\n",
       "      <td>945.79</td>\n",
       "      <td>1254574</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>8/7/2017</td>\n",
       "      <td>947.52</td>\n",
       "      <td>948.96</td>\n",
       "      <td>943.50</td>\n",
       "      <td>945.75</td>\n",
       "      <td>1445754</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>8/8/2017</td>\n",
       "      <td>944.29</td>\n",
       "      <td>952.49</td>\n",
       "      <td>942.48</td>\n",
       "      <td>944.19</td>\n",
       "      <td>1505064</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8/9/2017</td>\n",
       "      <td>938.45</td>\n",
       "      <td>943.76</td>\n",
       "      <td>933.92</td>\n",
       "      <td>940.08</td>\n",
       "      <td>1400852</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8/10/2017</td>\n",
       "      <td>935.00</td>\n",
       "      <td>936.30</td>\n",
       "      <td>921.78</td>\n",
       "      <td>923.59</td>\n",
       "      <td>2707393</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close   Volume   Name  Momentum  \\\n",
       "1252   8/4/2017  943.95  947.54  939.80  945.79  1254574  GOOGL         1   \n",
       "1253   8/7/2017  947.52  948.96  943.50  945.75  1445754  GOOGL        -1   \n",
       "1254   8/8/2017  944.29  952.49  942.48  944.19  1505064  GOOGL        -1   \n",
       "1255   8/9/2017  938.45  943.76  933.92  940.08  1400852  GOOGL        -1   \n",
       "1256  8/10/2017  935.00  936.30  921.78  923.59  2707393  GOOGL        -1   \n",
       "\n",
       "      Streak  Future Momentum  \n",
       "1252       1             -1.0  \n",
       "1253       0             -1.0  \n",
       "1254      -1             -1.0  \n",
       "1255      -2             -1.0  \n",
       "1256      -3              1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the tail to make sure the data looks good\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqUAAAJQCAYAAAC3hx2YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiISjkMpEREREQnHoZSIiIiIhPsPr5CZjIXx5mgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4df3b67f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a heatmap with the new features.\n",
    "\n",
    "corrmat = new_data.corr()\n",
    "\n",
    "# Set up the matplotlib figure.\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "# Draw the heatmap using seaborn\n",
    "sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Creation and Comparison of Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been analyzed to ensure it can be manipulated, it is time to create some predictive models. For comparison, the scores from the models will be stored in a new table, titled \"Model Comparison.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scoring Metric</th>\n",
       "      <th>Scoring Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Scoring Metric, Scoring Value]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table to store the scores for each model.\n",
    "# Title: Model Comparison\n",
    "# Columns: Model, R^2, Accuracy, AUROC\n",
    "# Model values: Linear Regression, Ridge Regression, Lasso Regression, Support Vector Regression, Gradient Boost Classification\n",
    "models = {'Model':[], 'Scoring Metric':[], 'Scoring Value':[]}\n",
    "columns = models.keys()\n",
    "model_comparison = pd.DataFrame(data=models, columns=columns)\n",
    "model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the variables. \n",
    "# Use the closing value for Y\n",
    "# Use the new features for X\n",
    "Y = data['Future Momentum']\n",
    "X = data[['Close', 'Volume', 'Momentum', 'Streak']]\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.8)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, Y_train = X[:offset], Y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, Y_test = X[offset:], Y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the Model:\n",
      "[[  0 117]\n",
      " [  0 135]]\n",
      "Accuracy Score:\n",
      "[ 0.52380952  0.52380952  0.52380952  0.52380952  0.52380952  0.52380952\n",
      "  0.52380952  0.52380952  0.528       0.52419355]\n",
      "Average of the Accuracy Score:\n",
      "0.524266973886\n"
     ]
    }
   ],
   "source": [
    "# Declare a logistic regression classifier.\n",
    "# Larger C's lead to reduced regularization of parameters, but because there are\n",
    "#   few features, the value of C has a trivial effect (tested for many C's)\n",
    "lr = LogisticRegression(C=1e9)\n",
    "\n",
    "# Fit the model.\n",
    "lr.fit(X_train,Y_train)\n",
    "y_pred = lr.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "\n",
    "print('Confusion Matrix of the Model:')\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# Use Accuracy for Logistic Regression Scoring Metric\n",
    "cv = cross_val_score(lr, X, Y, cv=10, scoring='accuracy') \n",
    "print('Accuracy Score:')\n",
    "print(cv)\n",
    "# Print the average of the R2 and store it in the table\n",
    "print('Average of the Accuracy Score:')\n",
    "print(cv.mean())\n",
    "\n",
    "# Store the data in the model_comparison table\n",
    "models = {'Model':['Logistic Regression'], 'Scoring Metric':'Accuracy', 'Scoring Value':[cv.mean()]}\n",
    "model_comparison = model_comparison.append(pd.DataFrame(data=models, columns=models.keys()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:\n",
      "[ -1.76650557e-03  -8.22193653e-03   9.58609575e-04  -3.54075289e-03\n",
      "  -8.63520489e-05  -3.15263337e-04  -1.85405358e-03  -1.19014702e-03\n",
      "  -5.36217513e-03  -5.70910153e-02]\n",
      "Average of the R2 Score:\n",
      "-0.00784695917995\n"
     ]
    }
   ],
   "source": [
    "# Fitting a ridge regression model. Alpha is the regularization\n",
    "# parameter (usually called lambda). As alpha gets larger, parameter\n",
    "# shrinkage grows more pronounced. Note that by convention, the\n",
    "# intercept is not regularized. Since we standardized the data\n",
    "# earlier, the intercept should be equal to zero and can be dropped.\n",
    "\n",
    "ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "ridgeregr.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = ridgeregr.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "# Print the R2.\n",
    "cv = cross_val_score(ridgeregr, X, Y, cv=10, scoring='r2') \n",
    "print('R2 Score:')\n",
    "print(cv)\n",
    "# Print the average of the R2 and store it in the table\n",
    "print('Average of the R2 Score:')\n",
    "print(cv.mean())\n",
    "\n",
    "# Store the data in the model_comparison table\n",
    "models = {'Model':['Ridge Regression'], 'Scoring Metric':'R2', 'Scoring Value':[cv.mean()]}\n",
    "model_comparison = model_comparison.append(pd.DataFrame(data=models, columns=models.keys()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6.11610631e-03   3.45111633e-02   8.37872952e-02   1.35004433e-01\n",
      "   6.62328123e-02   3.38155344e-02   8.76897298e-02   1.30740222e-01\n",
      "   1.80670674e-01   2.36850091e-01   2.83746358e-01   6.99301741e-02\n",
      "   1.15069255e-02  -8.60988998e-03   3.79933194e-02   7.10470293e-02\n",
      "   2.33898569e-02  -1.18423211e-02  -8.94430193e-03   4.02851857e-02\n",
      "   1.03484941e-01   8.26981284e-02   5.32546929e-02   7.12566929e-02\n",
      "   2.79542572e-02   1.13714133e-02   3.96495922e-02   6.58607893e-02\n",
      "   2.34709688e-02  -1.65520896e-02  -3.38924521e-03   4.63920667e-02\n",
      "   7.25057801e-02   4.63941366e-02   9.24559047e-02   7.85221218e-02\n",
      "   4.67170328e-02   7.02017875e-02   4.10222495e-02   6.69166251e-02\n",
      "   3.99851361e-02   7.51974828e-02   5.15926585e-02   6.30033364e-02\n",
      "   4.42545297e-02   6.71763892e-02   1.74369739e-02  -5.54167030e-03\n",
      "  -7.04423497e-02  -3.71022945e-03   2.91407588e-02  -2.28629109e-02\n",
      "   6.62414775e-03   5.31992150e-02   1.26168825e-01   1.34414804e-01\n",
      "   6.23822970e-02   1.13299449e-01   1.61676232e-01   2.06603509e-01\n",
      "   2.50965181e-01   8.53879637e-02   3.22271422e-02   3.14628804e-02\n",
      "   1.38079695e-01   1.38660750e-01   1.89113428e-01   1.04889492e-01\n",
      "   3.26053516e-02  -2.14348076e-02   4.50114366e-03   2.91718083e-02\n",
      "  -2.43309471e-02  -5.68862242e-03   8.08056184e-03   1.27707186e-04\n",
      "  -6.94306504e-02   1.42876479e-02   7.49829086e-02   7.94538004e-02\n",
      "   3.03180518e-02   3.00876536e-03   3.74702981e-02  -1.97382704e-02\n",
      "  -6.21983305e-02   1.05103225e-03   3.96856139e-02  -1.57026904e-02\n",
      "   4.02752373e-03   6.97552360e-02   7.03719298e-02   2.19579354e-02\n",
      "  -2.41621382e-03   3.93912138e-02   8.03943606e-02   6.43996552e-02\n",
      "   4.10654374e-02   8.64009252e-02   1.48976913e-01   8.47363534e-02\n",
      "   4.73105691e-02   7.19686488e-02   3.74558490e-02  -2.37248946e-02\n",
      "  -7.74522578e-03   2.31701736e-02  -4.55567731e-03   2.24489556e-02\n",
      "  -2.69500186e-03   1.70016304e-02  -1.03856750e-02   2.27604413e-02\n",
      "  -1.89806533e-03  -6.63857880e-02  -1.15470217e-01   4.00007235e-02\n",
      "   9.38872375e-02   1.37464827e-01   1.55059947e-01   2.08408898e-01\n",
      "   7.92232270e-02   2.72968843e-02  -2.49661962e-02  -6.69811705e-02\n",
      "  -1.23124607e-01  -1.73963846e-01  -2.17962192e-01  -2.69010086e-01\n",
      "  -3.16207417e-01  -4.35778020e-03   1.66272525e-02  -2.25044357e-02\n",
      "  -7.52333758e-02  -1.24572389e-01  -3.64965922e-03   4.40944821e-02\n",
      "   6.53944831e-02   4.48384313e-02   8.21782270e-02   4.21372511e-02\n",
      "   8.56791122e-02   1.35125426e-01   6.59921722e-02   1.72213715e-02\n",
      "  -2.47737590e-02  -7.35835081e-02  -1.25684666e-01  -1.76452072e-01\n",
      "  -2.19425573e-01  -2.72747950e-01  -3.05524860e-01  -3.09750381e-04\n",
      "   6.87821160e-02   9.31393805e-02   1.81436760e-01   2.05541595e-01\n",
      "   8.44606628e-02   2.72589431e-02  -2.25607337e-02  -1.27126172e-02\n",
      "   4.60567047e-02   8.52984840e-02   4.41761331e-02   1.03243404e-01\n",
      "   1.45164184e-01   1.85013099e-01   2.32261619e-01   2.79365935e-01\n",
      "   6.79327049e-02   3.83983015e-02   6.62364359e-02   3.56514491e-02\n",
      "   6.68923680e-02   2.05589029e-02  -8.01904637e-03   3.12018606e-02\n",
      "  -1.02622416e-02  -7.36608131e-02  -1.01155247e-01  -1.18399693e-01\n",
      "  -1.98371035e-01  -2.58879517e-01  -3.05882802e-01  -3.52093638e-01\n",
      "   1.79587801e-03   3.55009308e-02   3.34033557e-03   4.07128142e-02\n",
      "   6.65815101e-02   4.21408677e-02   7.29522083e-02   1.94969702e-02\n",
      "   1.89924087e-02   3.38646207e-02  -2.38226964e-02  -7.17997924e-02\n",
      "  -1.17087365e-01  -1.73983181e-01  -2.05684633e-01  -2.60857020e-01\n",
      "  -3.11919978e-01   4.30532184e-03   2.39061510e-02  -1.57607122e-02\n",
      "  -7.16914339e-02   8.13542546e-04   2.54026865e-02  -1.66867372e-02\n",
      "   4.40078089e-02   1.04027143e-01   8.68537232e-02   4.82484378e-02\n",
      "   1.15887621e-01   1.67205168e-01   7.57809846e-02   4.39461026e-02\n",
      "   6.94450942e-02   3.80425726e-02   7.78281231e-02   4.85353244e-02\n",
      "   1.16131874e-01   1.02109069e-01   8.32497787e-02   1.12772536e-01\n",
      "   1.49032268e-01   8.84172406e-02   5.85059150e-02   7.95612513e-02\n",
      "   2.66434919e-02  -2.17409738e-02  -6.73292536e-02  -1.17531097e-01\n",
      "  -1.75289840e-01   2.90875780e-03   2.61105722e-02  -2.24776089e-02\n",
      "  -1.98676957e-03   2.71944658e-02   3.08123738e-02   9.13168586e-02\n",
      "   6.30544313e-02   1.42542413e-01   8.28014667e-02   6.43987736e-02\n",
      "   7.27534579e-02   3.87907565e-02  -8.45236012e-03   2.25306443e-02\n",
      "  -1.75129475e-03   4.80704517e-02   9.44889771e-02   1.70023001e-01]\n",
      "0.0248827351445\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared of the model:\n",
      "-0.00506509809597\n",
      "R2 Score:\n",
      "[ -3.63098054e-03  -6.03070649e-03  -1.25221729e-05  -5.38314891e-03\n",
      "  -2.24001692e-03  -2.23524985e-03  -7.03649947e-04  -1.52310077e-03\n",
      "  -2.92184541e-03  -1.81842409e-02]\n",
      "Average of the R2 Score:\n",
      "-0.00428654619254\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha=.35)\n",
    "lasso.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = lasso.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "# Print the R-Squared value and store it in the table\n",
    "print('R-Squared of the model:') \n",
    "score = r2_score(Y_test, y_pred)\n",
    "print(score)\n",
    "\n",
    "# Print the R2.\n",
    "cv = cross_val_score(lasso, X, Y, cv=10, scoring='r2') \n",
    "print('R2 Score:')\n",
    "print(cv)\n",
    "# Print the average of the AUROC and store it in the table\n",
    "print('Average of the R2 Score:')\n",
    "print(cv.mean())\n",
    "\n",
    "# Store the data in the model_comparison table\n",
    "models = {'Model':['Lasso Regression'], 'Scoring Metric':'R2', 'Scoring Value':[cv.mean()]}\n",
    "model_comparison = model_comparison.append(pd.DataFrame(data=models, columns=models.keys()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01819434  0.01190747  0.01248952  0.01477884  0.01474742  0.01154773\n",
      "  0.01587317  0.01158112  0.01265028  0.01880232  0.01754783  0.01823242\n",
      "  0.01031514  0.01694348  0.01544584  0.01920144  0.01970914  0.02983377\n",
      "  0.01595673  0.01668389  0.02892383  0.02812542  0.02762186  0.0194102\n",
      "  0.02313997  0.03254737  0.01651319  0.01470491  0.01940745  0.02573599\n",
      "  0.02005754  0.0215444   0.0194931   0.02121356  0.01952579  0.02457242\n",
      "  0.02190444  0.01801882  0.01734174  0.01539571  0.01654107  0.02147733\n",
      "  0.02536582  0.01189664  0.01978194  0.01553389  0.01453216  0.0342353\n",
      "  0.02103702  0.01950323  0.02305828  0.019834    0.0274035   0.02608003\n",
      "  0.04565101  0.06828425  0.03392349  0.03595877  0.03654285  0.03390032\n",
      "  0.03057777  0.03011849  0.02605247  0.04816834  0.09539446  0.05762205\n",
      "  0.0599214   0.04681831  0.0277888   0.02319329  0.02807601  0.02484454\n",
      "  0.02094433  0.01984418  0.00829238  0.04034154  0.02353018  0.03585553\n",
      "  0.04597953  0.0270895   0.02605049  0.02688088  0.03113849  0.02413693\n",
      "  0.02837849  0.02390217  0.03182754  0.0263238   0.02591928  0.03978406\n",
      "  0.01771831  0.017749    0.02095446  0.01566671  0.00971123  0.01308859\n",
      "  0.01722618  0.01470427  0.02627228  0.02933246  0.02204442  0.01896359\n",
      "  0.0296131   0.01953323  0.01610085  0.01805434  0.01847704  0.01743287\n",
      "  0.02004825  0.01319106  0.01407658  0.01780463  0.03610087  0.02325312\n",
      "  0.02247205  0.05264588  0.05737821  0.05433505  0.02986062  0.03385176\n",
      "  0.02449231  0.02176964  0.01879648  0.02369095  0.0176725   0.01588937\n",
      "  0.01933456  0.01720932  0.0182798   0.01828473  0.01230357  0.01963377\n",
      "  0.01623529  0.01555841  0.01823352  0.01769262  0.01209586  0.01841292\n",
      "  0.02511304  0.01604604  0.01205779  0.01280736  0.01250432  0.01226095\n",
      "  0.01732419  0.01700185  0.01408152  0.01230387  0.01666695  0.01284679\n",
      "  0.02531611  0.02012836  0.03720265  0.01795275  0.0499441   0.03068075\n",
      "  0.02774489  0.02081966  0.01944007  0.01110111  0.01925207  0.02759212\n",
      "  0.01754391  0.02602043  0.02088062  0.01405835  0.01299848  0.01188776\n",
      "  0.01448089  0.0135093   0.01251981  0.01070724  0.01297904  0.01462369\n",
      "  0.01440528  0.02223383  0.02746277  0.01569574  0.03236519  0.05579725\n",
      "  0.03050403  0.02085508  0.02161802  0.02323895  0.01810537  0.02207066\n",
      "  0.01904394  0.01020342  0.00827288  0.01132456  0.01318505  0.00908972\n",
      "  0.03213209  0.02113808  0.01373596  0.01381224  0.01615729  0.00925345\n",
      "  0.02204418  0.01676314  0.01468022  0.01844749  0.01153034  0.01828053\n",
      "  0.01211206  0.01524293  0.01212258  0.01717865  0.05075297  0.06019456\n",
      "  0.02372381  0.0156032   0.03107372  0.03329878  0.01471462  0.01213739\n",
      "  0.00952948  0.00710461  0.01585336  0.01564447  0.03181026  0.03627016\n",
      "  0.04476316  0.02996728  0.02061733  0.02668187  0.02555844  0.01926206\n",
      "  0.01537838  0.01544016  0.01720304  0.01588102  0.00824671  0.01783731\n",
      "  0.0133419   0.0130942   0.01321952  0.01389391  0.05518506  0.0883894\n",
      "  0.02748427  0.05259538  0.02105032  0.02944124  0.01359519  0.02518027\n",
      "  0.01041084  0.01234446  0.01549037  0.016527    0.01497416  0.03710937]\n",
      "0.0228357109921\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:\n",
      "[ -3.24882390e-03  -1.91231150e-03  -5.44323850e-04  -1.91231150e-03\n",
      "  -1.04272341e-04  -3.24882390e-03  -1.61141748e-03  -2.41664551e-03\n",
      "  -2.62064570e-06  -1.38435358e-02]\n",
      "Average of the R2 Score:\n",
      "-0.00288450863917\n"
     ]
    }
   ],
   "source": [
    "# TODO: Look up the epsilon value for SVR\n",
    "# Changing value for epsilon may reduce the overfitting\n",
    "\n",
    "# Make a model using SVR here\n",
    "svr = SVR(epsilon=.5)\n",
    "svr.fit(X_train,Y_train)\n",
    "y_pred = svr.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "# Use Accuracy for the Scoring Metric\n",
    "cv = cross_val_score(svr, X, Y, cv=10, scoring='r2') \n",
    "print('R2 Score:')\n",
    "print(cv)\n",
    "# Print the average of the AUROC and store it in the table\n",
    "print('Average of the R2 Score:')\n",
    "print(cv.mean())\n",
    "\n",
    "# Store the data in the model_comparison table\n",
    "models = {'Model':['Support Vector Regression'], 'Scoring Metric':'R2', 'Scoring Value':[cv.mean()]}\n",
    "model_comparison = model_comparison.append(pd.DataFrame(data=models, columns=models.keys()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303]\n",
      "0.0213930348259\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the model:\n",
      "[[  0 117]\n",
      " [  0 135]]\n",
      "Accuracy Score:\n",
      "[ 0.52380952  0.52380952  0.52380952  0.52380952  0.52380952  0.52380952\n",
      "  0.52380952  0.52380952  0.528       0.52419355]\n",
      "Average of the Accuracy Score:\n",
      "0.524266973886\n"
     ]
    }
   ],
   "source": [
    "# Change the parameters C, gamma, and Kernal type to see if the model can be improved.\n",
    "# Write definitions of the parameters here.\n",
    "\n",
    "# Make a model using SVR here\n",
    "svc = SVC(C=.1)\n",
    "svc.fit(X_train,Y_train)\n",
    "y_pred = svc.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "print('Confusion Matrix of the model:')\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# Print the Accuracy.\n",
    "cv = cross_val_score(svc, X, Y, cv=10, scoring='accuracy') \n",
    "print('Accuracy Score:')\n",
    "print(cv)\n",
    "# Print the average of the AUROC and store it in the table\n",
    "print('Average of the Accuracy Score:')\n",
    "print(cv.mean())\n",
    "\n",
    "\n",
    "# Store the data in the model_comparison table\n",
    "models = {'Model':['Support Vector Classifier'], 'Scoring Metric':'Accuracy', 'Scoring Value':[cv.mean()]}\n",
    "model_comparison = model_comparison.append(pd.DataFrame(data=models, columns=models.keys()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of the model:\n",
      "[[68 49]\n",
      " [77 58]]\n",
      "Accuracy Score:\n",
      "[ 0.54761905  0.4047619   0.53174603  0.50793651  0.52380952  0.41269841\n",
      "  0.5         0.54761905  0.44        0.53225806]\n",
      "Average of the Accuracy Score:\n",
      "0.494844854071\n"
     ]
    }
   ],
   "source": [
    "# 500 iterations, using 5-deep trees, and loss function 'deviance.'\n",
    "# Play around with number of iterations\n",
    "# Look into learning rate\n",
    "\n",
    "### Document results of different numbers of n_estimators and max_depth. \n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 5,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train,Y_train)\n",
    "y_pred = clf.fit(X_train,Y_train).predict(X_test)\n",
    "\n",
    "print('Confusion Matrix of the model:')\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# Print the AUROC.\n",
    "cv = cross_val_score(clf, X, Y, cv=10, scoring='accuracy') \n",
    "print('Accuracy Score:')\n",
    "print(cv)\n",
    "# Print the average of the AUROC and store it in the table\n",
    "print('Average of the Accuracy Score:')\n",
    "print(cv.mean())\n",
    "\n",
    "# Store the data in the model_comparison table\n",
    "models = {'Model':['Gradient Boosting Classifier'], 'Scoring Metric':'Accuracy', 'Scoring Value':[cv.mean()]}\n",
    "model_comparison = model_comparison.append(pd.DataFrame(data=models, columns=models.keys()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.\n",
      " -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.\n",
      " -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1.\n",
      " -1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
      " -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.]\n",
      "-0.214285714286\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Selection and Analysis of the Best Performing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model comparison table here. Write up an analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scoring Metric</th>\n",
       "      <th>Scoring Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>-0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>-0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>-0.002885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.502781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>-0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>-0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>-0.002885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.524267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.497219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model Scoring Metric  Scoring Value\n",
       "0            Logistic Regression       Accuracy       0.524267\n",
       "1               Ridge Regression             R2      -0.007847\n",
       "2               Lasso Regression             R2      -0.004287\n",
       "3      Support Vector Regression             R2      -0.002885\n",
       "4      Support Vector Classifier       Accuracy       0.524267\n",
       "5   Gradient Boosting Classifier       Accuracy       0.502781\n",
       "6            Logistic Regression       Accuracy       0.524267\n",
       "7            Logistic Regression       Accuracy       0.524267\n",
       "8      Support Vector Classifier       Accuracy       0.524267\n",
       "9      Support Vector Classifier       Accuracy       0.524267\n",
       "10              Ridge Regression             R2      -0.007847\n",
       "11              Lasso Regression             R2      -0.004287\n",
       "12     Support Vector Regression             R2      -0.002885\n",
       "13     Support Vector Classifier       Accuracy       0.524267\n",
       "14  Gradient Boosting Classifier       Accuracy       0.497219"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of table goes here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Being provided one thousand dollars cash every ten business days, how will the top three models perform compared to one another as well as to a 401(k) approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a cash_available list that stores how much cash is available \n",
    "# to buy the stocks. It will be $1000 every ten business days.\n",
    "cash_available = [1000]\n",
    "\n",
    "# Create a list for stocks and cash\n",
    "\n",
    "# Start out with 0 stocks_owned\n",
    "stocks_owned = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pred_return function to calculate the returns of the prediction models\n",
    "def pred_return(y_pred, data, cash_available, stocks_owned):\n",
    "    # Create DataFrame for values\n",
    "    new_values = {'Stocks':[],'Cash':[]}\n",
    "    columns = new_values.keys()\n",
    "    values = pd.DataFrame(data=new_values, columns=columns)\n",
    "    for i in range(len(y_pred)):\n",
    "        # For every tenth iteration of i, add 1000 to cash_available\n",
    "        if i%10 == 0:\n",
    "            cash_available = cash_available+1000\n",
    "        # If the predicted value is greater than zero, buy more stock\n",
    "        if y_pred[i] > 0:\n",
    "            [stocks_owned,cash_available] = buy_stock(cash_available, \n",
    "                                                      stocks_owned, y_pred, \n",
    "                                                      data.Close[i])\n",
    "        # If the predicted value is less than zero, sell stock\n",
    "        elif y_pred[i] < 0:\n",
    "            [stocks_owned,cash_available] = sell_stock(cash_available, \n",
    "                                                      stocks_owned, y_pred, \n",
    "                                                      data.Close[i])\n",
    "        stocks_owned = [stocks_owned,cash_available][0]\n",
    "        cash_available = [stocks_owned,cash_available][1]\n",
    "        new_values = {'Stocks':[stocks_owned], 'Cash':[cash_available]}\n",
    "        values = values.append(pd.DataFrame(data=new_values, columns=\n",
    "                                            new_values.keys()), \n",
    "                                            ignore_index=True)\n",
    "    print(values,y_pred)\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a buy_stock function that buys as many stocks as can be afforded\n",
    "def buy_stock(cash_available, stocks_owned, y_pred, value):\n",
    "    # Set number of stocks to buy\n",
    "    num_stocks_buy = int(cash_available/value)\n",
    "    # Subtract from cash_available, store it in a list\n",
    "    cash_available = cash_available-num_stocks_buy*value\n",
    "    stocks_owned = stocks_owned+num_stocks_buy\n",
    "    return(stocks_owned, cash_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a sell_stock function that sells all stocks\n",
    "def sell_stock(cash_available, stocks_owned, y_pred, value):\n",
    "    sell_value = stocks_owned*value\n",
    "    cash_available = cash_available + sell_value\n",
    "    stocks_owned = 0\n",
    "    return(stocks_owned, cash_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the 401k approach simulator, safe_invest, \n",
    "# That buys as much stock as is available every two weeks / ten business days.\n",
    "def safe_invest(data, cash_available, stocks_owned):\n",
    "    # Create DataFrame for values\n",
    "    new_values = {'Stocks':[],'Cash':[]}\n",
    "    columns = new_values.keys()\n",
    "    values = pd.DataFrame(data=new_values, columns=columns)\n",
    "    for i in range(len(data.loc[offset:,:])):\n",
    "        # For every tenth iteration of i, add 1000 to cash_available\n",
    "        if i%10 == 0:\n",
    "            cash_available = cash_available+1000\n",
    "        num_stocks_buy = int(cash_available/data.Close[i])\n",
    "        stocks_owned = num_stocks_buy + stocks_owned\n",
    "        cash_available = cash_available-num_stocks_buy*data.Close[i]\n",
    "        # Store the values in a table\n",
    "        new_values = {'Stocks':[stocks_owned], 'Cash':[cash_available]}\n",
    "        values = values.append(pd.DataFrame(data=new_values, columns=\n",
    "                                            new_values.keys()), \n",
    "                                            ignore_index=True)\n",
    "\n",
    "    print(values)\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stocks    Cash\n",
      "0       3.0    8.98\n",
      "1       3.0    8.98\n",
      "2       3.0    8.98\n",
      "3       3.0    8.98\n",
      "4       3.0    8.98\n",
      "5       3.0    8.98\n",
      "6       3.0    8.98\n",
      "7       3.0    8.98\n",
      "8       3.0    8.98\n",
      "9       3.0    8.98\n",
      "10      6.0    4.16\n",
      "11      6.0    4.16\n",
      "12      6.0    4.16\n",
      "13      6.0    4.16\n",
      "14      6.0    4.16\n",
      "15      6.0    4.16\n",
      "16      6.0    4.16\n",
      "17      6.0    4.16\n",
      "18      6.0    4.16\n",
      "19      6.0    4.16\n",
      "20      8.0  311.28\n",
      "21      8.0  311.28\n",
      "22      8.0  311.28\n",
      "23      8.0  311.28\n",
      "24      8.0  311.28\n",
      "25      8.0  311.28\n",
      "26      8.0  311.28\n",
      "27      8.0  311.28\n",
      "28      8.0  311.28\n",
      "29      8.0  311.28\n",
      "..      ...     ...\n",
      "222    60.0  270.05\n",
      "223    60.0  270.05\n",
      "224    60.0  270.05\n",
      "225    60.0  270.05\n",
      "226    60.0  270.05\n",
      "227    60.0  270.05\n",
      "228    60.0  270.05\n",
      "229    60.0  270.05\n",
      "230    62.0  349.53\n",
      "231    62.0  349.53\n",
      "232    62.0  349.53\n",
      "233    62.0  349.53\n",
      "234    62.0  349.53\n",
      "235    62.0  349.53\n",
      "236    62.0  349.53\n",
      "237    62.0  349.53\n",
      "238    62.0  349.53\n",
      "239    62.0  349.53\n",
      "240    65.0   11.80\n",
      "241    65.0   11.80\n",
      "242    65.0   11.80\n",
      "243    65.0   11.80\n",
      "244    65.0   11.80\n",
      "245    65.0   11.80\n",
      "246    65.0   11.80\n",
      "247    65.0   11.80\n",
      "248    65.0   11.80\n",
      "249    65.0   11.80\n",
      "250    67.0  129.66\n",
      "251    67.0  129.66\n",
      "\n",
      "[252 rows x 2 columns] [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Run the pred_return function for lr\n",
    "y_pred = lr.fit(X_train,Y_train).predict(X_test)\n",
    "cash_available = 0\n",
    "stocks_owned = 0\n",
    "values = pred_return(y_pred, data, cash_available, stocks_owned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29297.44\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ending returns from the lr model\n",
    "lr_returns = values.loc[len(values)-1,'Stocks']*data.loc[len(y_pred)-1,'Close'] + values.loc[len(values)-1, 'Cash']\n",
    "print(lr_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21737.44\n"
     ]
    }
   ],
   "source": [
    "# 252 trading days in a year, 2017-2012 is 6 years, \n",
    "# $1000 granted every 10 days = 151,200 dollars granted.\n",
    "# Since we are predicting the last 20% of the data, divide by 20\n",
    "# Get total profit by subrtracting returns by dollars granted. \n",
    "lr_profit = lr_returns - 7560\n",
    "print(lr_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stocks    Cash\n",
      "0       3.0    8.98\n",
      "1       3.0    8.98\n",
      "2       3.0    8.98\n",
      "3       3.0    8.98\n",
      "4       3.0    8.98\n",
      "5       3.0    8.98\n",
      "6       3.0    8.98\n",
      "7       3.0    8.98\n",
      "8       3.0    8.98\n",
      "9       3.0    8.98\n",
      "10      6.0    4.16\n",
      "11      6.0    4.16\n",
      "12      6.0    4.16\n",
      "13      6.0    4.16\n",
      "14      6.0    4.16\n",
      "15      6.0    4.16\n",
      "16      6.0    4.16\n",
      "17      6.0    4.16\n",
      "18      6.0    4.16\n",
      "19      6.0    4.16\n",
      "20      8.0  311.28\n",
      "21      8.0  311.28\n",
      "22      8.0  311.28\n",
      "23      8.0  311.28\n",
      "24      8.0  311.28\n",
      "25      8.0  311.28\n",
      "26      8.0  311.28\n",
      "27      8.0  311.28\n",
      "28      8.0  311.28\n",
      "29      8.0  311.28\n",
      "..      ...     ...\n",
      "222    60.0  270.05\n",
      "223    60.0  270.05\n",
      "224    60.0  270.05\n",
      "225    60.0  270.05\n",
      "226    60.0  270.05\n",
      "227    60.0  270.05\n",
      "228    60.0  270.05\n",
      "229    60.0  270.05\n",
      "230    62.0  349.53\n",
      "231    62.0  349.53\n",
      "232    62.0  349.53\n",
      "233    62.0  349.53\n",
      "234    62.0  349.53\n",
      "235    62.0  349.53\n",
      "236    62.0  349.53\n",
      "237    62.0  349.53\n",
      "238    62.0  349.53\n",
      "239    62.0  349.53\n",
      "240    65.0   11.80\n",
      "241    65.0   11.80\n",
      "242    65.0   11.80\n",
      "243    65.0   11.80\n",
      "244    65.0   11.80\n",
      "245    65.0   11.80\n",
      "246    65.0   11.80\n",
      "247    65.0   11.80\n",
      "248    65.0   11.80\n",
      "249    65.0   11.80\n",
      "250    67.0  129.66\n",
      "251    67.0  129.66\n",
      "\n",
      "[252 rows x 2 columns] [ 0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303\n",
      "  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303  0.02139303]\n"
     ]
    }
   ],
   "source": [
    "# Run the pred_return function for svr\n",
    "y_pred = svr.fit(X_train,Y_train).predict(X_test)\n",
    "cash_available = 0\n",
    "stocks_owned = 0\n",
    "values = pred_return(y_pred, data, cash_available, stocks_owned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#values.to_csv('D:\\\\GitHub\\\\Thinkful_Unit_3\\\\svr_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29297.44\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ending returns from the svr model\n",
    "svr_returns = values.loc[len(values)-1,'Stocks']*data.loc[len(y_pred)-1,'Close'] + values.loc[len(values)-1, 'Cash']\n",
    "print(svr_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21737.44\n"
     ]
    }
   ],
   "source": [
    "# 252 trading days in a year, 2017-2012 is 6 years, \n",
    "# $1000 granted every 10 days = 151,200 dollars granted.\n",
    "# Get total profit by subrtracting returns by dollars granted. \n",
    "svr_profit = svr_returns - 7560\n",
    "print(svr_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stocks    Cash\n",
      "0       3.0    8.98\n",
      "1       3.0    8.98\n",
      "2       3.0    8.98\n",
      "3       3.0    8.98\n",
      "4       3.0    8.98\n",
      "5       3.0    8.98\n",
      "6       3.0    8.98\n",
      "7       3.0    8.98\n",
      "8       3.0    8.98\n",
      "9       3.0    8.98\n",
      "10      6.0    4.16\n",
      "11      6.0    4.16\n",
      "12      6.0    4.16\n",
      "13      6.0    4.16\n",
      "14      6.0    4.16\n",
      "15      6.0    4.16\n",
      "16      6.0    4.16\n",
      "17      6.0    4.16\n",
      "18      6.0    4.16\n",
      "19      6.0    4.16\n",
      "20      8.0  311.28\n",
      "21      8.0  311.28\n",
      "22      8.0  311.28\n",
      "23      8.0  311.28\n",
      "24      8.0  311.28\n",
      "25      8.0  311.28\n",
      "26      8.0  311.28\n",
      "27      8.0  311.28\n",
      "28      8.0  311.28\n",
      "29      8.0  311.28\n",
      "..      ...     ...\n",
      "222    60.0  270.05\n",
      "223    60.0  270.05\n",
      "224    60.0  270.05\n",
      "225    60.0  270.05\n",
      "226    60.0  270.05\n",
      "227    60.0  270.05\n",
      "228    60.0  270.05\n",
      "229    60.0  270.05\n",
      "230    62.0  349.53\n",
      "231    62.0  349.53\n",
      "232    62.0  349.53\n",
      "233    62.0  349.53\n",
      "234    62.0  349.53\n",
      "235    62.0  349.53\n",
      "236    62.0  349.53\n",
      "237    62.0  349.53\n",
      "238    62.0  349.53\n",
      "239    62.0  349.53\n",
      "240    65.0   11.80\n",
      "241    65.0   11.80\n",
      "242    65.0   11.80\n",
      "243    65.0   11.80\n",
      "244    65.0   11.80\n",
      "245    65.0   11.80\n",
      "246    65.0   11.80\n",
      "247    65.0   11.80\n",
      "248    65.0   11.80\n",
      "249    65.0   11.80\n",
      "250    67.0  129.66\n",
      "251    67.0  129.66\n",
      "\n",
      "[252 rows x 2 columns] [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Run the pred_return function for svc\n",
    "y_pred = svc.fit(X_train,Y_train).predict(X_test)\n",
    "cash_available = 0\n",
    "stocks_owned = 0\n",
    "values = pred_return(y_pred, data, cash_available, stocks_owned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29297.44\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ending returns from the svc model\n",
    "svc_returns = values.loc[len(values)-1,'Stocks']*data.loc[len(y_pred)-1,'Close'] + values.loc[len(values)-1, 'Cash']\n",
    "print(svc_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21737.44\n"
     ]
    }
   ],
   "source": [
    "# 252 trading days in a year, 2017-2012 is 6 years, \n",
    "# $1000 granted every 10 days = 151,200 dollars granted.\n",
    "# Get total profit by subrtracting returns by dollars granted. \n",
    "svc_profit = svc_returns - 7560\n",
    "print(svc_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stocks      Cash\n",
      "0       0.0   1000.00\n",
      "1       0.0   1000.00\n",
      "2       2.0    331.80\n",
      "3       2.0    331.80\n",
      "4       0.0   1009.62\n",
      "5       2.0    333.40\n",
      "6       2.0    333.40\n",
      "7       2.0    333.40\n",
      "8       2.0    333.40\n",
      "9       2.0    333.40\n",
      "10      5.0    328.58\n",
      "11      5.0    328.58\n",
      "12      0.0   2050.33\n",
      "13      6.0      3.25\n",
      "14      6.0      3.25\n",
      "15      6.0      3.25\n",
      "16      6.0      3.25\n",
      "17      0.0   2103.55\n",
      "18      5.0    336.40\n",
      "19      5.0    336.40\n",
      "20      0.0   3068.60\n",
      "21      0.0   3068.60\n",
      "22      0.0   3068.60\n",
      "23      8.0    227.08\n",
      "24      8.0    227.08\n",
      "25      0.0   3103.08\n",
      "26      8.0    190.20\n",
      "27      0.0   3105.56\n",
      "28      8.0    166.68\n",
      "29      0.0   3167.16\n",
      "..      ...       ...\n",
      "222     0.0  24020.63\n",
      "223     0.0  24020.63\n",
      "224     0.0  24020.63\n",
      "225     0.0  24020.63\n",
      "226     0.0  24020.63\n",
      "227     0.0  24020.63\n",
      "228     0.0  24020.63\n",
      "229     0.0  24020.63\n",
      "230    54.0    166.59\n",
      "231     0.0  24992.01\n",
      "232     0.0  24992.01\n",
      "233     0.0  24992.01\n",
      "234     0.0  24992.01\n",
      "235     0.0  24992.01\n",
      "236     0.0  24992.01\n",
      "237     0.0  24992.01\n",
      "238     0.0  24992.01\n",
      "239    56.0    263.53\n",
      "240     0.0  26234.49\n",
      "241     0.0  26234.49\n",
      "242     0.0  26234.49\n",
      "243     0.0  26234.49\n",
      "244    57.0    416.34\n",
      "245     0.0  25993.95\n",
      "246     0.0  25993.95\n",
      "247     0.0  25993.95\n",
      "248     0.0  25993.95\n",
      "249     0.0  25993.95\n",
      "250    61.0     88.68\n",
      "251     0.0  26644.42\n",
      "\n",
      "[252 rows x 2 columns] [-1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.\n",
      " -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      " -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.\n",
      " -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1.\n",
      "  1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.\n",
      " -1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1.\n",
      " -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
      " -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Run the pred_return function for gradient boosting classifier\n",
    "y_pred = clf.fit(X_train,Y_train).predict(X_test)\n",
    "cash_available = 0\n",
    "stocks_owned = 0\n",
    "values = pred_return(y_pred, data, cash_available, stocks_owned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26644.42\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ending returns from the clf model\n",
    "clf_returns = values.loc[len(values)-1,'Stocks']*data.loc[len(y_pred)-1,'Close'] + values.loc[len(values)-1, 'Cash']\n",
    "print(clf_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19084.42\n"
     ]
    }
   ],
   "source": [
    "# 252 trading days in a year, 2017-2012 is 6 years, \n",
    "# $1000 granted every 10 days = 151,200 dollars granted.\n",
    "# Get total profit by subrtracting returns by dollars granted. \n",
    "clf_profit = clf_returns - 7560\n",
    "print(clf_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Stocks    Cash\n",
      "0       3.0    8.98\n",
      "1       3.0    8.98\n",
      "2       3.0    8.98\n",
      "3       3.0    8.98\n",
      "4       3.0    8.98\n",
      "5       3.0    8.98\n",
      "6       3.0    8.98\n",
      "7       3.0    8.98\n",
      "8       3.0    8.98\n",
      "9       3.0    8.98\n",
      "10      6.0    4.16\n",
      "11      6.0    4.16\n",
      "12      6.0    4.16\n",
      "13      6.0    4.16\n",
      "14      6.0    4.16\n",
      "15      6.0    4.16\n",
      "16      6.0    4.16\n",
      "17      6.0    4.16\n",
      "18      6.0    4.16\n",
      "19      6.0    4.16\n",
      "20      8.0  311.28\n",
      "21      8.0  311.28\n",
      "22      8.0  311.28\n",
      "23      8.0  311.28\n",
      "24      8.0  311.28\n",
      "25      8.0  311.28\n",
      "26      8.0  311.28\n",
      "27      8.0  311.28\n",
      "28      8.0  311.28\n",
      "29      8.0  311.28\n",
      "..      ...     ...\n",
      "222    60.0  270.05\n",
      "223    60.0  270.05\n",
      "224    60.0  270.05\n",
      "225    60.0  270.05\n",
      "226    60.0  270.05\n",
      "227    60.0  270.05\n",
      "228    60.0  270.05\n",
      "229    60.0  270.05\n",
      "230    62.0  349.53\n",
      "231    62.0  349.53\n",
      "232    62.0  349.53\n",
      "233    62.0  349.53\n",
      "234    62.0  349.53\n",
      "235    62.0  349.53\n",
      "236    62.0  349.53\n",
      "237    62.0  349.53\n",
      "238    62.0  349.53\n",
      "239    62.0  349.53\n",
      "240    65.0   11.80\n",
      "241    65.0   11.80\n",
      "242    65.0   11.80\n",
      "243    65.0   11.80\n",
      "244    65.0   11.80\n",
      "245    65.0   11.80\n",
      "246    65.0   11.80\n",
      "247    65.0   11.80\n",
      "248    65.0   11.80\n",
      "249    65.0   11.80\n",
      "250    67.0  129.66\n",
      "251    67.0  129.66\n",
      "\n",
      "[252 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Run the safe_invest function\n",
    "cash_available = 0\n",
    "stocks_owned = 0\n",
    "values = safe_invest(data, cash_available, stocks_owned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29297.44\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ending returns from the safe_invest function\n",
    "safe_returns = values.loc[len(values)-1,'Stocks']*data.loc[len(data.loc[offset:,:])-1,'Close'] + values.loc[len(values)-1, 'Cash']\n",
    "print(safe_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21737.44\n"
     ]
    }
   ],
   "source": [
    "# 252 trading days in a year, 2017-2012 is 6 years, \n",
    "# $1000 granted every 10 days = 151,200 dollars granted.\n",
    "# Get total profit by subrtracting returns by dollars granted. \n",
    "safe_profit = safe_returns - 7560\n",
    "print(safe_profit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
